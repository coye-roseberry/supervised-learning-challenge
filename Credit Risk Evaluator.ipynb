{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['index', 'Unnamed: 0'])\n",
    "train_df_backup = train_df.copy()\n",
    "\n",
    "######\n",
    "\n",
    "test_df = test_df.drop(columns=['index', 'Unnamed: 0'])\n",
    "test_df_backup = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "\n",
    "train_df_X = train_df.drop(columns=['loan_status'])\n",
    "train_df_dummy_X = pd.get_dummies(train_df_X, drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "train_df_dummy_y = pd.get_dummies(train_df['loan_status'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_df_X = test_df.drop(columns=['loan_status'])\n",
    "test_df_dummy_X = pd.get_dummies(test_df_X, drop_first=True)\n",
    "\n",
    "\n",
    "test_df_dummy_y = pd.get_dummies(test_df['loan_status'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['debt_settlement_flag_Y'] added to testing set\n"
     ]
    }
   ],
   "source": [
    "# add missing dummy variables to testing set\n",
    "\n",
    "test_columns = list(test_df_dummy_X.columns)\n",
    "train_columns = list(train_df_dummy_X.columns)\n",
    "#######\n",
    "dummy_col_list = []\n",
    "#######\n",
    "\n",
    "for  col in train_columns:\n",
    "    if col not in test_columns:\n",
    "        dummy_col_list.append(col)\n",
    "\n",
    "for col in dummy_col_list:\n",
    "    test_df_dummy_X[f'{col}'] = 0\n",
    "\n",
    "\n",
    "print(f'{dummy_col_list} added to testing set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction #1\n",
    "\n",
    "Since the data is unscaled, I expect the Logistic Regression model to perform worse than the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model Training Data Score: 0.7042692939244664\n",
      "Logistic Regression model Testing Data Score: 0.5752871118672905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xanroseberry/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "\n",
    "classifier_log_regression = LogisticRegression(max_iter=10000)\n",
    "\n",
    "classifier_log_regression.fit(train_df_dummy_X, train_df_dummy_y.values.ravel())\n",
    "\n",
    "lr_train_score = classifier_log_regression.score(train_df_dummy_X, train_df_dummy_y)\n",
    "lr_test_score = classifier_log_regression.score(test_df_dummy_X,test_df_dummy_y)\n",
    "\n",
    "print(f\"Logistic Regression model Training Data Score: {lr_train_score}\")\n",
    "\n",
    "print(f\"Logistic Regression model Testing Data Score: {lr_test_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier model Training Data Score: 1.0\n",
      "Random Forest Classifier model Testing Data Score: 0.6405784772437261\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "classifier_rand_forest = RandomForestClassifier(random_state=1, n_estimators=1000)\n",
    "\n",
    "classifier_rand_forest.fit(train_df_dummy_X, train_df_dummy_y.values.ravel())\n",
    "\n",
    "rf_train_score = classifier_rand_forest.score(train_df_dummy_X, train_df_dummy_y.values.ravel())\n",
    "\n",
    "rf_test_score = classifier_rand_forest.score(test_df_dummy_X,test_df_dummy_y.values.ravel())\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Random Forest Classifier model Training Data Score: {rf_train_score}\")\n",
    "\n",
    "print(f\"Random Forest Classifier model Testing Data Score: {rf_test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction # 2\n",
    "\n",
    "In the last experiment, I did not expect the percent difference to be so relatively small between the two models. With the scaled data, I expect the Logistical regression scores to increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(train_df_dummy_X)\n",
    "\n",
    "train_df_dummy_X_scaled = scaler.transform(train_df_dummy_X)\n",
    "test_df_dummy_X_scaled = scaler.transform(test_df_dummy_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model Scaled Training Data Score: 0.7078817733990148\n",
      "Logistic Regression model Scaled Testing Data Score: 0.7679710761378137\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier_log_regression_scaled = LogisticRegression(max_iter=10000)\n",
    "classifier_log_regression_scaled.fit(train_df_dummy_X_scaled, train_df_dummy_y.values.ravel())\n",
    "\n",
    "\n",
    "lr_train_score_scaled = classifier_log_regression_scaled.score(train_df_dummy_X_scaled, train_df_dummy_y)\n",
    "lr_test_score_scaled = classifier_log_regression_scaled.score(test_df_dummy_X_scaled,test_df_dummy_y)\n",
    "\n",
    "print(f\"Logistic Regression model Scaled Training Data Score: {lr_train_score_scaled}\")\n",
    "\n",
    "print(f\"Logistic Regression model Scaled Testing Data Score: {lr_test_score_scaled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier model Training Data Score: 1.0\n",
      "Random Forest Classifier model Testing Data Score: 0.6407911527009783\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "\n",
    "classifier_rand_forest_scaled = RandomForestClassifier(random_state=1, n_estimators=1000)\n",
    "\n",
    "classifier_rand_forest_scaled.fit(train_df_dummy_X_scaled, train_df_dummy_y.values.ravel())\n",
    "\n",
    "rf_train_score_scaled = classifier_rand_forest_scaled.score(train_df_dummy_X_scaled, train_df_dummy_y)\n",
    "\n",
    "rf_test_score_scaled = classifier_rand_forest_scaled.score(test_df_dummy_X_scaled,test_df_dummy_y)\n",
    "\n",
    "print(f\"Random Forest Classifier model Training Data Score: {rf_train_score_scaled}\")\n",
    "\n",
    "print(f\"Random Forest Classifier model Testing Data Score: {rf_test_score_scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results & Thoughts\n",
    "\n",
    "The outputs for my unscaled and scaled Random Forest Classifier models were virtually the same. I did not expext this. I expected the score to be high\n",
    "\n",
    "I also noticed that the iterations for the Logistical Regression model had great improvement from increasing the number of iterations\n",
    "\n",
    "The test score for my scaled logistic regression model was higre than the training score. I did not expect this to occur. Perhaps this is due to more qualified borrowers in the training set."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2094152f125268bc958a064fbe92a1188de787ebe03a7f14f859e3d4f2603a0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
